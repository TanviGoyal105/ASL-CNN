{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9adYTpKs947U"
      },
      "source": [
        "#Step 1: Dataset Selection and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbTQsjFL9x6x"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "train_df = pd.read_csv('sign_mnist_train.csv')   # read from the training dataset and convert to dataframe\n",
        "test_df = pd.read_csv('sign_mnist_test.csv')     # read from the test dataset and convert to dataframe\n",
        "\n",
        "# print dimensions of the datasets\n",
        "# print('Training shape:', train_df.shape)\n",
        "# print('Testing shape :', test_df.shape)\n",
        "\n",
        "X_train = train_df.drop(columns=['label']).values\n",
        "X_test = test_df.drop(columns=['label']).values\n",
        "\n",
        "y_train = train_df['label'].values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0  # Reshape to (28, 28, 1) and normalize\n",
        "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0    # Reshape to (28, 28, 1) and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "_QMjc3hTDXyZ",
        "outputId": "9ad31e8f-b232-47bc-ff28-2d442f5ee3b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-73e4147b-5a9d-48d2-b45e-0734e28fcafc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73e4147b-5a9d-48d2-b45e-0734e28fcafc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73e4147b-5a9d-48d2-b45e-0734e28fcafc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73e4147b-5a9d-48d2-b45e-0734e28fcafc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df941bf7-8847-4d7e-9a1f-3a841d0c34f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df941bf7-8847-4d7e-9a1f-3a841d0c34f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df941bf7-8847-4d7e-9a1f-3a841d0c34f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     13     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()  # get first 5 rows of training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "o3W5KAnyhIrE",
        "outputId": "0c215e8e-3c53-4328-8304-f619e9b667bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image dimensions: 28 x 28 x 1\n",
            "Number of classes: 24\n",
            "Label map: {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y'}\n",
            "Total number of images: 27455\n",
            "Average number of images per label: 1143.9583333333333\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAHWCAYAAADdKxJLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUAhJREFUeJzt3XlcVPXi//H3IKvIIiqbCuKS+5ZbpJkLiaamaalFiWZ6MzTNrpmVG2WmmZpmmt1yuelt8eaSt0zcK8kFw11TMzUVKBVwB+H8/ujL/BxBRAJmTr2ej8c8cs75zJz3GWhm3pzNYhiGIQAAAAAAYEpO9g4AAAAAAAAKj2IPAAAAAICJUewBAAAAADAxij0AAAAAACZGsQcAAAAAwMQo9gAAAAAAmBjFHgAAAAAAE6PYAwAAAABgYhR7AAAAAABMjGIPAHA4VapUUb9+/ewd408bP368LBZLiSyrTZs2atOmjfX+xo0bZbFYtHTp0hJZfr9+/VSlSpUSWVZetm3bJldXVx0/frxElpfz+m7cuPGOH/vLL7/IYrFowYIFRZ7LUdxzzz168cUX7R0DAP42KPYAgBJz9OhR/eMf/1DVqlXl7u4ub29vtWzZUu+8846uXLli73j5WrBggSwWi/Xm7u6u4OBgRUZGaubMmbpw4UKRLOf06dMaP368EhMTi+T5ipIjZ3vllVf02GOPKTQ01Drtvffe+0uXZ3vbv3+/xo8fr19++SXXvFGjRmn27NlKSkoq+WAA8DfkbO8AAIC/h//973969NFH5ebmpr59+6pevXrKyMjQd999p5EjR2rfvn2aN2+evWPeVmxsrMLCwpSZmamkpCRt3LhRw4cP17Rp07Ry5Uo1aNDAOvbVV1/VSy+9dEfPf/r0aU2YMEFVqlRRo0aNCvy4NWvW3NFyCiO/bB988IGys7OLPUNeEhMTtXbtWm3ZssVm+nvvvafy5csXy94frVu31pUrV+Tq6nrHjw0NDdWVK1fk4uJS5LlK0v79+zVhwgS1adMm194a3bp1k7e3t9577z3FxsbaJyAA/I1Q7AEAxe7YsWPq06ePQkNDtX79egUFBVnnxcTE6MiRI/rf//5nx4QF16lTJzVt2tR6f/To0Vq/fr26dOmihx56SAcOHJCHh4ckydnZWc7OxftRe/nyZZUuXbpQBbMo2bOkzp8/XyEhIbrnnnsK/RyXLl2Sp6dngcc7OTnJ3d29UMvK2ePjr8zJyUmPPPKIFi1apAkTJpTYISkA8HfFrvgAgGI3ZcoUXbx4UR9++KFNqc9RvXp1DRs27JaPP3funP75z3+qfv36KlOmjLy9vdWpUyft2rUr19hZs2apbt26Kl26tMqWLaumTZtqyZIl1vkXLlzQ8OHDVaVKFbm5ucnf318PPPCAdu7cWej1a9euncaMGaPjx4/r448/tk7P6xj7uLg4tWrVSr6+vipTpoxq1qypl19+WdIfx203a9ZMktS/f3/rbv85u5O3adNG9erVU0JCglq3bq3SpUtbH3vzMfY5srKy9PLLLyswMFCenp566KGHdPLkSZsxtzqnwY3PebtseR1jf+nSJb3wwguqXLmy3NzcVLNmTU2dOlWGYdiMs1gsGjJkiJYvX6569erJzc1NdevW1erVq/N+wW+yfPlytWvXzua1rlKlivbt26dNmzZZs+asS85hFZs2bdKzzz4rf39/VapUSZJ0/PhxPfvss6pZs6Y8PDxUrlw5Pfroo7l2N8/rGPucn8/+/fvVtm1blS5dWhUrVtSUKVNsHpvXMfb9+vVTmTJldOrUKXXv3l1lypRRhQoV9M9//lNZWVk2jz979qyefPJJeXt7y9fXV9HR0dq1a1eBjtvPzMzUhAkTVKNGDbm7u6tcuXJq1aqV4uLibMYdPHhQjzzyiPz8/OTu7q6mTZtq5cqV1vkLFizQo48+Kklq27at9TW+8fV44IEHdPz4cYc8dAMA/mrYYg8AKHZffvmlqlatqnvvvbdQj//555+1fPlyPfroowoLC1NycrLef/993X///dq/f7+Cg4Ml/bE7+HPPPadHHnlEw4YN09WrV7V7925t3bpVjz/+uCTpmWee0dKlSzVkyBDVqVNHZ8+e1XfffacDBw7o7rvvLvQ6Pvnkk3r55Ze1Zs0aDRw4MM8x+/btU5cuXdSgQQPFxsbKzc1NR44c0ffffy9Jql27tmJjYzV27FgNGjRI9913nyTZvG5nz55Vp06d1KdPHz3xxBMKCAjIN9fEiRNlsVg0atQopaSkaMaMGYqIiFBiYqJ1z4KCKEi2GxmGoYceekgbNmzQgAED1KhRI33zzTcaOXKkTp06penTp9uM/+677/TFF1/o2WeflZeXl2bOnKmePXvqxIkTKleu3C1znTp1SidOnMj1s5sxY4aGDh2qMmXK6JVXXpGkXK/Vs88+qwoVKmjs2LG6dOmSJGn79u3asmWL+vTpo0qVKumXX37RnDlz1KZNG+3fv1+lS5fO93U6f/68OnbsqB49eqhXr15aunSpRo0apfr166tTp075PjYrK0uRkZFq0aKFpk6dqrVr1+rtt99WtWrVNHjwYElSdna2unbtqm3btmnw4MGqVauWVqxYoejo6HyfO8f48eM1adIkPf3002revLnS09O1Y8cO7dy5Uw888ICkP35PW7ZsqYoVK+qll16Sp6enPvvsM3Xv3l3//e9/9fDDD6t169Z67rnnNHPmTL388suqXbu2JFn/K0lNmjSRJH3//fdq3LhxgfIBAArJAACgGKWlpRmSjG7duhX4MaGhoUZ0dLT1/tWrV42srCybMceOHTPc3NyM2NhY67Ru3boZdevWzfe5fXx8jJiYmAJnyTF//nxDkrF9+/Z8n7tx48bW++PGjTNu/KidPn26Icn47bffbvkc27dvNyQZ8+fPzzXv/vvvNyQZc+fOzXPe/fffb72/YcMGQ5JRsWJFIz093Tr9s88+MyQZ77zzjnXaza/3rZ4zv2zR0dFGaGio9f7y5csNScbrr79uM+6RRx4xLBaLceTIEes0SYarq6vNtF27dhmSjFmzZuVa1o3Wrl1rSDK+/PLLXPPq1q1rkz9Hzs+yVatWxvXr123mXb58Odf4+Ph4Q5KxaNEi67Sc13fDhg3WaTk/nxvHXbt2zQgMDDR69uxpnXbs2LFcr2N0dLQhyeb32TAMo3HjxkaTJk2s9//73/8akowZM2ZYp2VlZRnt2rW75c/mRg0bNjQ6d+6c75j27dsb9evXN65evWqdlp2dbdx7771GjRo1rNM+//zzXK/BzVxdXY3BgwfnuzwAwJ/HrvgAgGKVnp4uSfLy8ir0c7i5ucnJ6Y+PrKysLJ09e9a6G/uNu9D7+vrq119/1fbt22/5XL6+vtq6datOnz5d6Dy3UqZMmXzPju/r6ytJWrFiRaFPNOfm5qb+/fsXeHzfvn1tXvtHHnlEQUFB+uqrrwq1/IL66quvVKpUKT333HM201944QUZhqGvv/7aZnpERISqVatmvd+gQQN5e3vr559/znc5Z8+elSSVLVv2jjMOHDhQpUqVspl2414MmZmZOnv2rKpXry5fX98CHa5RpkwZPfHEE9b7rq6uat68+W3XI8czzzxjc/++++6zeezq1avl4uJis1eIk5OTYmJiCvT8vr6+2rdvnw4fPpzn/HPnzmn9+vXq1auXLly4oN9//12///67zp49q8jISB0+fFinTp0q0LKkP34uv//+e4HHAwAKh2IPAChW3t7ekvSnLgeXnZ2t6dOnq0aNGnJzc1P58uVVoUIF7d69W2lpadZxo0aNUpkyZdS8eXPVqFFDMTEx1t3cc0yZMkV79+5V5cqV1bx5c40fP77Apet2Ll68mO8fMHr37q2WLVvq6aefVkBAgPr06aPPPvvsjkp+xYoV7+hEeTVq1LC5b7FYVL169TwvUVaUjh8/ruDg4FyvR86u2jdfbz4kJCTXc5QtW1bnz58v0PKMm47bL4iwsLBc065cuaKxY8dazwuQ87uWmppq87t2K5UqVcp1XoWCroe7u7sqVKiQ72OPHz+uoKCgXIcEVK9e/bbPL/1xVYfU1FTdddddql+/vkaOHKndu3db5x85ckSGYWjMmDGqUKGCzW3cuHGSpJSUlAItS/rj58KJ8wCg+FHsAQDFytvbW8HBwdq7d2+hn+ONN97QiBEj1Lp1a3388cf65ptvFBcXp7p169qU4tq1a+vQoUP65JNP1KpVK/33v/9Vq1atrIVEknr16qWff/5Zs2bNUnBwsN566y3VrVs31xbkO/Xrr78qLS0t34Ll4eGhzZs3a+3atXryySe1e/du9e7dWw888ECuE6Tl9xxF7VbFq6CZisLNW85z3K6w5xx/X9A/ANwor9dy6NChmjhxonr16qXPPvtMa9asUVxcnMqVK1egP8AUdj3ye2xRat26tY4ePaqPPvpI9erV07/+9S/dfffd+te//iVJ1nX85z//qbi4uDxvBf0jgiSlpqaqfPnyxbIuAID/j5PnAQCKXZcuXTRv3jzFx8crPDz8jh+/dOlStW3bVh9++KHN9LxKg6enp3r37q3evXsrIyNDPXr00MSJEzV69GjrJcaCgoL07LPP6tlnn1VKSoruvvtuTZw48bYnN8vPv//9b0lSZGRkvuOcnJzUvn17tW/fXtOmTdMbb7yhV155RRs2bFBERESRb928eZdrwzB05MgRNWjQwDqtbNmySk1NzfXY48ePq2rVqtb7d5ItNDRUa9eu1YULF2y22h88eNA6vyjUqlVL0h+XVLxZYV7LpUuXKjo6Wm+//bZ12tWrV/N8fewhNDRUGzZssF7mMMeRI0cK/Bx+fn7q37+/+vfvr4sXL6p169YaP368nn76aevP28XFRREREfk+z+1e31OnTikjI8PmhHoAgOLBFnsAQLF78cUX5enpqaefflrJycm55h89elTvvPPOLR9fqlSpXFs8P//881zH+uYcb53D1dVVderUkWEYyszMVFZWVq7dqf39/RUcHKxr167d6WpZrV+/Xq+99prCwsIUFRV1y3Hnzp3LNa1Ro0aSZF1+zrXUi6pILlq0yOYwiKVLl+rMmTM2f8SoVq2afvjhB2VkZFinrVq1Ktdl8e4k24MPPqisrCy9++67NtOnT58ui8Xyp/6IcqOKFSuqcuXK2rFjR655np6ed/w65vW7NmvWrBLdeyE/kZGRyszM1AcffGCdlp2drdmzZxfo8Tf/P1KmTBlVr17d+vvn7++vNm3a6P3339eZM2dyPf63336z/vt2vw8JCQmSbn3lBABA0WGLPQCg2FWrVk1LlixR7969Vbt2bfXt21f16tVTRkaGtmzZos8//zzP66jn6NKli2JjY9W/f3/de++92rNnjxYvXmyzNVmSOnTooMDAQLVs2VIBAQE6cOCA3n33XXXu3FleXl5KTU1VpUqV9Mgjj6hhw4YqU6aM1q5dq+3bt9tsoc3P119/rYMHD+r69etKTk7W+vXrFRcXp9DQUK1cudK6V0BeYmNjtXnzZnXu3FmhoaFKSUnRe++9p0qVKqlVq1bW18rX11dz586Vl5eXPD091aJFizyPBy8IPz8/tWrVSv3791dycrJmzJih6tWr25x87emnn9bSpUvVsWNH9erVS0ePHtXHH39sczK7O83WtWtXtW3bVq+88op++eUXNWzYUGvWrNGKFSs0fPjwXM/9Z3Tr1k3Lli3LdTx3kyZNNGfOHL3++uuqXr26/P391a5du3yfq0uXLvr3v/8tHx8f1alTR/Hx8Vq7dm2+l9wrSd27d1fz5s31wgsv6MiRI6pVq5ZWrlxp/aPR7bai16lTR23atFGTJk3k5+enHTt2WC//mGP27Nlq1aqV6tevr4EDB6pq1apKTk5WfHy8fv31V+3atUvSH3+UKlWqlCZPnqy0tDS5ubmpXbt28vf3lyTFxcUpJCSES90BQEmw09n4AQB/Qz/99JMxcOBAo0qVKoarq6vh5eVltGzZ0pg1a5bNpbXyutzdCy+8YAQFBRkeHh5Gy5Ytjfj4+FyXY3v//feN1q1bG+XKlTPc3NyMatWqGSNHjjTS0tIMw/jj0mMjR440GjZsaHh5eRmenp5Gw4YNjffee++22XMukZZzc3V1NQIDA40HHnjAeOedd2wuKZfj5svdrVu3zujWrZsRHBxsuLq6GsHBwcZjjz1m/PTTTzaPW7FihVGnTh3D2dnZ5hJm999//y0v53ery9395z//MUaPHm34+/sbHh4eRufOnY3jx4/nevzbb79tVKxY0XBzczNatmxp7NixI9dz5pft5svdGYZhXLhwwXj++eeN4OBgw8XFxahRo4bx1ltvGdnZ2TbjJOV5CcJbXYbvZjt37jQkGd9++63N9KSkJKNz586Gl5eXIcm6LvlduvD8+fNG//79jfLlyxtlypQxIiMjjYMHD+bKcqvL3eX187n5tbnV5e48PT1zPfbm3yHDMIzffvvNePzxxw0vLy/Dx8fH6Nevn/H9998bkoxPPvkkn1fKMF5//XWjefPmhq+vr+Hh4WHUqlXLmDhxopGRkWEz7ujRo0bfvn2NwMBAw8XFxahYsaLRpUsXY+nSpTbjPvjgA6Nq1apGqVKlbF6PrKwsIygoyHj11VfzzQMAKBoWwyjEaWQBAAAcSPv27RUcHGw918HfzfLly/Xwww/ru+++U8uWLe0dR8uXL9fjjz+uo0ePKigoyN5xAOAvj2IPAABMb+vWrbrvvvt0+PDhIjsxn6O6cuWKzRn9s7Ky1KFDB+3YsUNJSUnFcuWEOxUeHq777rtPU6ZMsXcUAPhboNgDAACYyNNPP60rV64oPDxc165d0xdffKEtW7bojTfe0OjRo+0dDwBgBxR7AAAAE1myZInefvttHTlyRFevXlX16tU1ePBgmxPgAQD+Xij2AAAAAACYGNexBwAAAADAxCj2AAAAAACYmLO9A5hBdna2Tp8+LS8vL1ksFnvHAQAAAAD8xRmGoQsXLig4OFhOTvlvk6fYF8Dp06dVuXJle8cAAAAAAPzNnDx5UpUqVcp3DMW+ALy8vCT98YJ6e3vbOQ0AAAAA4K8uPT1dlStXtvbR/FDsCyBn93tvb2+KPQAAAACgxBTkcHBOngcAAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBizvYOAAAAABSHJiMX2W3ZCW/1tduyAfz9sMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMY+wBAADwp3AsOwDYF1vsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAm5mzvAAAAmFmTkYvstuyEt/rabdkAAMBxsMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlx8jwAAAAA+IviJK9/D2yxBwAAAADAxCj2AAAAAACYmF2L/ebNm9W1a1cFBwfLYrFo+fLl1nmZmZkaNWqU6tevL09PTwUHB6tv3746ffq0zXOcO3dOUVFR8vb2lq+vrwYMGKCLFy/ajNm9e7fuu+8+ubu7q3LlypoyZUpJrB4AAAAAAMXOrsX+0qVLatiwoWbPnp1r3uXLl7Vz506NGTNGO3fu1BdffKFDhw7poYceshkXFRWlffv2KS4uTqtWrdLmzZs1aNAg6/z09HR16NBBoaGhSkhI0FtvvaXx48dr3rx5xb5+AAAAAAAUN7uePK9Tp07q1KlTnvN8fHwUFxdnM+3dd99V8+bNdeLECYWEhOjAgQNavXq1tm/frqZNm0qSZs2apQcffFBTp05VcHCwFi9erIyMDH300UdydXVV3bp1lZiYqGnTptn8AQAAAAAAADMy1Vnx09LSZLFY5OvrK0mKj4+Xr6+vtdRLUkREhJycnLR161Y9/PDDio+PV+vWreXq6modExkZqcmTJ+v8+fMqW7ZsruVcu3ZN165ds95PT08vvpUCTIyzrAIAAAD2Z5pif/XqVY0aNUqPPfaYvL29JUlJSUny9/e3Gefs7Cw/Pz8lJSVZx4SFhdmMCQgIsM7Lq9hPmjRJEyZMKI7VAAAAAPjjOIAiZYpin5mZqV69eskwDM2ZM6fYlzd69GiNGDHCej89PV2VK1cu9uXCvviABQDwWQAAMCOHL/Y5pf748eNav369dWu9JAUGBiolJcVm/PXr13Xu3DkFBgZaxyQnJ9uMybmfM+Zmbm5ucnNzK8rVAAAAAACgWDj0dexzSv3hw4e1du1alStXzmZ+eHi4UlNTlZCQYJ22fv16ZWdnq0WLFtYxmzdvVmZmpnVMXFycatasmedu+AAAAAAAmIldt9hfvHhRR44csd4/duyYEhMT5efnp6CgID3yyCPauXOnVq1apaysLOtx835+fnJ1dVXt2rXVsWNHDRw4UHPnzlVmZqaGDBmiPn36KDg4WJL0+OOPa8KECRowYIBGjRqlvXv36p133tH06dPtss4AAACAI+OQFMB87Frsd+zYobZt21rv5xzXHh0drfHjx2vlypWSpEaNGtk8bsOGDWrTpo0kafHixRoyZIjat28vJycn9ezZUzNnzrSO9fHx0Zo1axQTE6MmTZqofPnyGjt2LJe6AwAAAAD8Jdi12Ldp00aGYdxyfn7zcvj5+WnJkiX5jmnQoIG+/fbbO84HAAAAAICjc+hj7AEAAAAAQP4o9gAAAAAAmBjFHgAAAAAAE3P469gDAEoGZ0EGAAAlie8eRYdiDwAAAMAUKIJA3tgVHwAAAAAAE6PYAwAAAABgYuyKDwAAShS70gIAULTYYg8AAAAAgImxxR4liq00AAAAAFC02GIPAAAAAICJUewBAAAAADAxij0AAAAAACZGsQcAAAAAwMQ4eV4hcRI4AAAAAIAjYIs9AAAAAAAmxhZ7AAAAAABuYLY9tCn2AACHZ7YPVwAAgJLErvgAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMS53B+AvicujAfir4X0NAHArbLEHAAAAAMDE2GIPAAAAAH8Ce9TA3thiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGJcxx4AgL8orqsMAMDfA1vsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmZtdiv3nzZnXt2lXBwcGyWCxavny5zXzDMDR27FgFBQXJw8NDEREROnz4sM2Yc+fOKSoqSt7e3vL19dWAAQN08eJFmzG7d+/WfffdJ3d3d1WuXFlTpkwp7lUDAAAAAKBEONtz4ZcuXVLDhg311FNPqUePHrnmT5kyRTNnztTChQsVFhamMWPGKDIyUvv375e7u7skKSoqSmfOnFFcXJwyMzPVv39/DRo0SEuWLJEkpaenq0OHDoqIiNDcuXO1Z88ePfXUU/L19dWgQYNKdH0BQJKajFxkt2UnvNXXbssGAABA8bBrse/UqZM6deqU5zzDMDRjxgy9+uqr6tatmyRp0aJFCggI0PLly9WnTx8dOHBAq1ev1vbt29W0aVNJ0qxZs/Tggw9q6tSpCg4O1uLFi5WRkaGPPvpIrq6uqlu3rhITEzVt2rS/bLGnNAAAAADA34fDHmN/7NgxJSUlKSIiwjrNx8dHLVq0UHx8vCQpPj5evr6+1lIvSREREXJyctLWrVutY1q3bi1XV1frmMjISB06dEjnz5/Pc9nXrl1Tenq6zQ0AAAAAAEfksMU+KSlJkhQQEGAzPSAgwDovKSlJ/v7+NvOdnZ3l5+dnMyav57hxGTebNGmSfHx8rLfKlSv/+RUCAAAAAKAYOGyxt6fRo0crLS3Nejt58qS9IwEAAAAAkCeHLfaBgYGSpOTkZJvpycnJ1nmBgYFKSUmxmX/9+nWdO3fOZkxez3HjMm7m5uYmb29vmxsAAAAAAI7IYYt9WFiYAgMDtW7dOuu09PR0bd26VeHh4ZKk8PBwpaamKiEhwTpm/fr1ys7OVosWLaxjNm/erMzMTOuYuLg41axZU2XLli2htQEAAAAAoHjYtdhfvHhRiYmJSkxMlPTHCfMSExN14sQJWSwWDR8+XK+//rpWrlypPXv2qG/fvgoODlb37t0lSbVr11bHjh01cOBAbdu2Td9//72GDBmiPn36KDg4WJL0+OOPy9XVVQMGDNC+ffv06aef6p133tGIESPstNYAAAAAABQdu17ubseOHWrbtq31fk7Zjo6O1oIFC/Tiiy/q0qVLGjRokFJTU9WqVSutXr3aeg17SVq8eLGGDBmi9u3by8nJST179tTMmTOt8318fLRmzRrFxMSoSZMmKl++vMaOHfuXvdQdAAAAAODvxa7Fvk2bNjIM45bzLRaLYmNjFRsbe8sxfn5+WrJkSb7LadCggb799ttC5wQAAAAAwFE57DH2AAAAAADg9ij2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgInZ9XJ3AG6vychFdlt2wlt97bZsAAAAAAXDFnsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATo9gDAAAAAGBiFHsAAAAAAEyMYg8AAAAAgIlR7AEAAAAAMDGKPQAAAAAAJkaxBwAAAADAxCj2AAAAAACYGMUeAAAAAAATc+hin5WVpTFjxigsLEweHh6qVq2aXnvtNRmGYR1jGIbGjh2roKAgeXh4KCIiQocPH7Z5nnPnzikqKkre3t7y9fXVgAEDdPHixZJeHQAAAAAAipxDF/vJkydrzpw5evfdd3XgwAFNnjxZU6ZM0axZs6xjpkyZopkzZ2ru3LnaunWrPD09FRkZqatXr1rHREVFad++fYqLi9OqVau0efNmDRo0yB6rBAAAAABAkXK2d4D8bNmyRd26dVPnzp0lSVWqVNF//vMfbdu2TdIfW+tnzJihV199Vd26dZMkLVq0SAEBAVq+fLn69OmjAwcOaPXq1dq+fbuaNm0qSZo1a5YefPBBTZ06VcHBwfZZOQAAAAAAioBDb7G/9957tW7dOv3000+SpF27dum7775Tp06dJEnHjh1TUlKSIiIirI/x8fFRixYtFB8fL0mKj4+Xr6+vtdRLUkREhJycnLR169Y8l3vt2jWlp6fb3AAAAAAAcEQOvcX+pZdeUnp6umrVqqVSpUopKytLEydOVFRUlCQpKSlJkhQQEGDzuICAAOu8pKQk+fv728x3dnaWn5+fdczNJk2apAkTJhT16gAAAAAAUOQceov9Z599psWLF2vJkiXauXOnFi5cqKlTp2rhwoXFutzRo0crLS3Nejt58mSxLg8AAAAAgMJy6C32I0eO1EsvvaQ+ffpIkurXr6/jx49r0qRJio6OVmBgoCQpOTlZQUFB1sclJyerUaNGkqTAwEClpKTYPO/169d17tw56+Nv5ubmJjc3t2JYIwAAAAAAipZDb7G/fPmynJxsI5YqVUrZ2dmSpLCwMAUGBmrdunXW+enp6dq6davCw8MlSeHh4UpNTVVCQoJ1zPr165Wdna0WLVqUwFoAAAAAAFB8HHqLfdeuXTVx4kSFhISobt26+vHHHzVt2jQ99dRTkiSLxaLhw4fr9ddfV40aNRQWFqYxY8YoODhY3bt3lyTVrl1bHTt21MCBAzV37lxlZmZqyJAh6tOnD2fEBwAAAACYnkMX+1mzZmnMmDF69tlnlZKSouDgYP3jH//Q2LFjrWNefPFFXbp0SYMGDVJqaqpatWql1atXy93d3Tpm8eLFGjJkiNq3by8nJyf17NlTM2fOtMcqAQAAAABQpBy62Ht5eWnGjBmaMWPGLcdYLBbFxsYqNjb2lmP8/Py0ZMmSYkgIAAAAAIB9OfQx9gAAAAAAIH8UewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGKFKvZVq1bV2bNnc01PTU1V1apV/3QoAAAAAABQMIUq9r/88ouysrJyTb927ZpOnTr1p0MBAAAAAICCcb6TwStXrrT++5tvvpGPj4/1flZWltatW6cqVaoUWTgAAAAAAJC/Oyr23bt3lyRZLBZFR0fbzHNxcVGVKlX09ttvF1k4AAAAAACQvzsq9tnZ2ZKksLAwbd++XeXLly+WUAAAAAAAoGDuqNjnOHbsWFHnAAAAAAAAhVCoYi9J69at07p165SSkmLdkp/jo48++tPBAAAAAADA7RWq2E+YMEGxsbFq2rSpgoKCZLFYijoXAAAAAAAogEIV+7lz52rBggV68sknizoPAAAAAAC4A4W6jn1GRobuvffeos4CAAAAAADuUKGK/dNPP60lS5YUdRYAAAAAAHCHCrUr/tWrVzVv3jytXbtWDRo0kIuLi838adOmFUk4AAAAAACQv0IV+927d6tRo0aSpL1799rM40R6AAAAAACUnEIV+w0bNhR1DgAAAAAAUAiFOsYeAAAAAAA4hkJtsW/btm2+u9yvX7++0IEAAAAAAEDBFarY5xxfnyMzM1OJiYnau3evoqOjiyIXAAAAAAAogEIV++nTp+c5ffz48bp48eKfCgQAAAAAAAquSI+xf+KJJ/TRRx8V5VMCAAAAAIB8FGmxj4+Pl7u7e1E+JQAAAAAAyEehdsXv0aOHzX3DMHTmzBnt2LFDY8aMKZJgAAAAAADg9gpV7H18fGzuOzk5qWbNmoqNjVWHDh2KJBgAAAAAALi9QhX7+fPnF3UOAAAAAABQCIUq9jkSEhJ04MABSVLdunXVuHHjIgkFAAAAAAAKplDFPiUlRX369NHGjRvl6+srSUpNTVXbtm31ySefqEKFCkWZEQAAAAAA3EKhzoo/dOhQXbhwQfv27dO5c+d07tw57d27V+np6XruueeKOiMAAAAAALiFQm2xX716tdauXavatWtbp9WpU0ezZ8/m5HkAAAAAAJSgQm2xz87OlouLS67pLi4uys7O/tOhAAAAAABAwRSq2Ldr107Dhg3T6dOnrdNOnTql559/Xu3bty+ycAAAAAAAIH+FKvbvvvuu0tPTVaVKFVWrVk3VqlVTWFiY0tPTNWvWrKLOCAAAAAAAbqFQx9hXrlxZO3fu1Nq1a3Xw4EFJUu3atRUREVGk4QAAAAAAQP7uaIv9+vXrVadOHaWnp8tiseiBBx7Q0KFDNXToUDVr1kx169bVt99+W1xZAQAAAADATe6o2M+YMUMDBw6Ut7d3rnk+Pj76xz/+oWnTphVZOAAAAAAAkL87Kva7du1Sx44dbzm/Q4cOSkhI+NOhAAAAAABAwdxRsU9OTs7zMnc5nJ2d9dtvv/3pUAAAAAAAoGDuqNhXrFhRe/fuveX83bt3Kygo6E+HAgAAAAAABXNHxf7BBx/UmDFjdPXq1Vzzrly5onHjxqlLly5FFg4AAAAAAOTvjor9q6++qnPnzumuu+7SlClTtGLFCq1YsUKTJ09WzZo1de7cOb3yyitFGvDUqVN64oknVK5cOXl4eKh+/frasWOHdb5hGBo7dqyCgoLk4eGhiIgIHT582OY5zp07p6ioKHl7e8vX11cDBgzQxYsXizQnAAAAAAD2cEfXsQ8ICNCWLVs0ePBgjR49WoZhSJIsFosiIyM1e/ZsBQQEFFm48+fPq2XLlmrbtq2+/vprVahQQYcPH1bZsmWtY6ZMmaKZM2dq4cKFCgsL05gxYxQZGan9+/fL3d1dkhQVFaUzZ84oLi5OmZmZ6t+/vwYNGqQlS5YUWVYAAAAAAOzhjoq9JIWGhuqrr77S+fPndeTIERmGoRo1atiU7aIyefJkVa5cWfPnz7dOCwsLs/7bMAzNmDFDr776qrp16yZJWrRokQICArR8+XL16dNHBw4c0OrVq7V9+3Y1bdpUkjRr1iw9+OCDmjp1qoKDg4s8NwAAAAAAJeWOdsW/UdmyZdWsWTM1b968WEq9JK1cuVJNmzbVo48+Kn9/fzVu3FgffPCBdf6xY8eUlJSkiIgI6zQfHx+1aNFC8fHxkqT4+Hj5+vpaS70kRUREyMnJSVu3bs1zudeuXVN6errNDQAAAAAAR1ToYl8Sfv75Z82ZM0c1atTQN998o8GDB+u5557TwoULJUlJSUmSlGv3/4CAAOu8pKQk+fv728x3dnaWn5+fdczNJk2aJB8fH+utcuXKRb1qAAAAAAAUCYcu9tnZ2br77rv1xhtvqHHjxho0aJAGDhyouXPnFutyR48erbS0NOvt5MmTxbo8AAAAAAAKy6GLfVBQkOrUqWMzrXbt2jpx4oQkKTAwUJKUnJxsMyY5Odk6LzAwUCkpKTbzr1+/rnPnzlnH3MzNzU3e3t42NwAAAAAAHJFDF/uWLVvq0KFDNtN++uknhYaGSvrjRHqBgYFat26ddX56erq2bt2q8PBwSVJ4eLhSU1OVkJBgHbN+/XplZ2erRYsWJbAWAAAAAAAUnzs+K35Jev7553XvvffqjTfeUK9evbRt2zbNmzdP8+bNk/THZfaGDx+u119/XTVq1LBe7i44OFjdu3eX9McW/o4dO1p34c/MzNSQIUPUp08fzogPAAAAADA9hy72zZo107JlyzR69GjFxsYqLCxMM2bMUFRUlHXMiy++qEuXLmnQoEFKTU1Vq1attHr1aus17CVp8eLFGjJkiNq3by8nJyf17NlTM2fOtMcqAQAAAABQpBy62EtSly5d1KVLl1vOt1gsio2NVWxs7C3H+Pn5acmSJcURDwAAAAAAu3LoY+wBAAAAAED+KPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATMxUxf7NN9+UxWLR8OHDrdOuXr2qmJgYlStXTmXKlFHPnj2VnJxs87gTJ06oc+fOKl26tPz9/TVy5Ehdv369hNMDAAAAAFD0TFPst2/frvfff18NGjSwmf7888/ryy+/1Oeff65Nmzbp9OnT6tGjh3V+VlaWOnfurIyMDG3ZskULFy7UggULNHbs2JJeBQAAAAAAipwpiv3FixcVFRWlDz74QGXLlrVOT0tL04cffqhp06apXbt2atKkiebPn68tW7bohx9+kCStWbNG+/fv18cff6xGjRqpU6dOeu211zR79mxlZGTYa5UAAAAAACgSpij2MTEx6ty5syIiImymJyQkKDMz02Z6rVq1FBISovj4eElSfHy86tevr4CAAOuYyMhIpaena9++fXku79q1a0pPT7e5AQAAAADgiJztHeB2PvnkE+3cuVPbt2/PNS8pKUmurq7y9fW1mR4QEKCkpCTrmBtLfc78nHl5mTRpkiZMmFAE6QEAAAAAKF4OvcX+5MmTGjZsmBYvXix3d/cSW+7o0aOVlpZmvZ08ebLElg0AAAAAwJ1w6GKfkJCglJQU3X333XJ2dpazs7M2bdqkmTNnytnZWQEBAcrIyFBqaqrN45KTkxUYGChJCgwMzHWW/Jz7OWNu5ubmJm9vb5sbAAAAAACOyKGLffv27bVnzx4lJiZab02bNlVUVJT13y4uLlq3bp31MYcOHdKJEycUHh4uSQoPD9eePXuUkpJiHRMXFydvb2/VqVOnxNcJAAAAAICi5NDH2Ht5ealevXo20zw9PVWuXDnr9AEDBmjEiBHy8/OTt7e3hg4dqvDwcN1zzz2SpA4dOqhOnTp68sknNWXKFCUlJenVV19VTEyM3NzcSnydAAAAAAAoSg5d7Ati+vTpcnJyUs+ePXXt2jVFRkbqvffes84vVaqUVq1apcGDBys8PFyenp6Kjo5WbGysHVMDAAAAAFA0TFfsN27caHPf3d1ds2fP1uzZs2/5mNDQUH311VfFnAwAAAAAgJLn0MfYAwAAAACA/FHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABNz6GI/adIkNWvWTF5eXvL391f37t116NAhmzFXr15VTEyMypUrpzJlyqhnz55KTk62GXPixAl17txZpUuXlr+/v0aOHKnr16+X5KoAAAAAAFAsHLrYb9q0STExMfrhhx8UFxenzMxMdejQQZcuXbKOef755/Xll1/q888/16ZNm3T69Gn16NHDOj8rK0udO3dWRkaGtmzZooULF2rBggUaO3asPVYJAAAAAIAi5WzvAPlZvXq1zf0FCxbI399fCQkJat26tdLS0vThhx9qyZIlateunSRp/vz5ql27tn744Qfdc889WrNmjfbv36+1a9cqICBAjRo10muvvaZRo0Zp/PjxcnV1tceqAQAAAABQJBx6i/3N0tLSJEl+fn6SpISEBGVmZioiIsI6platWgoJCVF8fLwkKT4+XvXr11dAQIB1TGRkpNLT07Vv3748l3Pt2jWlp6fb3AAAAAAAcESmKfbZ2dkaPny4WrZsqXr16kmSkpKS5OrqKl9fX5uxAQEBSkpKso65sdTnzM+Zl5dJkybJx8fHeqtcuXIRrw0AAAAAAEXDNMU+JiZGe/fu1SeffFLsyxo9erTS0tKst5MnTxb7MgEAAAAAKAyHPsY+x5AhQ7Rq1Spt3rxZlSpVsk4PDAxURkaGUlNTbbbaJycnKzAw0Dpm27ZtNs+Xc9b8nDE3c3Nzk5ubWxGvBQAAAAAARc+ht9gbhqEhQ4Zo2bJlWr9+vcLCwmzmN2nSRC4uLlq3bp112qFDh3TixAmFh4dLksLDw7Vnzx6lpKRYx8TFxcnb21t16tQpmRUBAAAAAKCYOPQW+5iYGC1ZskQrVqyQl5eX9Zh4Hx8feXh4yMfHRwMGDNCIESPk5+cnb29vDR06VOHh4brnnnskSR06dFCdOnX05JNPasqUKUpKStKrr76qmJgYtsoDAAAAAEzPoYv9nDlzJElt2rSxmT5//nz169dPkjR9+nQ5OTmpZ8+eunbtmiIjI/Xee+9Zx5YqVUqrVq3S4MGDFR4eLk9PT0VHRys2NrakVgMAAAAAgGLj0MXeMIzbjnF3d9fs2bM1e/bsW44JDQ3VV199VZTRAAAAAABwCA59jD0AAAAAAMgfxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwsb9VsZ89e7aqVKkid3d3tWjRQtu2bbN3JAAAAAAA/pS/TbH/9NNPNWLECI0bN047d+5Uw4YNFRkZqZSUFHtHAwAAAACg0P42xX7atGkaOHCg+vfvrzp16mju3LkqXbq0PvroI3tHAwAAAACg0JztHaAkZGRkKCEhQaNHj7ZOc3JyUkREhOLj43ONv3btmq5du2a9n5aWJklKT0+3Tsu6dqUYE+fvxhx5IVvezJrNUXNJZLsVs2Zz1FwS2W7FrNkcNZdEtlsxazZHzSWR7VbMms1Rc0lkuxUzZMv5r2EYt32MxSjIKJM7ffq0KlasqC1btig8PNw6/cUXX9SmTZu0detWm/Hjx4/XhAkTSjomAAAAAAA2Tp48qUqVKuU75m+xxf5OjR49WiNGjLDez87O1rlz51SuXDlZLJY//fzp6emqXLmyTp48KW9v7z/9fEXJUbM5ai6JbIXlqNkcNZdEtsJy1GyOmksiW2E5ajZHzSWRrbAcNZuj5pLIVliOms1Rc0lFm80wDF24cEHBwcG3Hfu3KPbly5dXqVKllJycbDM9OTlZgYGBuca7ubnJzc3NZpqvr2+R5/L29na4X8QcjprNUXNJZCssR83mqLkkshWWo2Zz1FwS2QrLUbM5ai6JbIXlqNkcNZdEtsJy1GyOmksqumw+Pj4FGve3OHmeq6urmjRponXr1lmnZWdna926dTa75gMAAAAAYDZ/iy32kjRixAhFR0eradOmat68uWbMmKFLly6pf//+9o4GAAAAAECh/W2Kfe/evfXbb79p7NixSkpKUqNGjbR69WoFBASUeBY3NzeNGzcu1+7+jsBRszlqLolsheWo2Rw1l0S2wnLUbI6aSyJbYTlqNkfNJZGtsBw1m6PmkshWWI6azVFzSfbL9rc4Kz4AAAAAAH9Vf4tj7AEAAAAA+Kui2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsS9js2bNVpUoVubu7q0WLFtq2bZu9I0mSNm/erK5duyo4OFgWi0XLly+3dyRJ0qRJk9SsWTN5eXnJ399f3bt316FDh+wdS5I0Z84cNWjQQN7e3vL29lZ4eLi+/vpre8fK5c0335TFYtHw4cPtHUXjx4+XxWKxudWqVcvesaxOnTqlJ554QuXKlZOHh4fq16+vHTt22DuWqlSpkut1s1gsiomJsWuurKwsjRkzRmFhYfLw8FC1atX02muvyR7nZL3de5hhGBo7dqyCgoLk4eGhiIgIHT582CGyffHFF+rQoYPKlSsni8WixMTEEsl1u2yZmZkaNWqU6tevL09PTwUHB6tv3746ffq03bNJf7yf1KpVS56enipbtqwiIiK0detWu+e60TPPPCOLxaIZM2YUe66CZOvXr1+u95GOHTs6RDZJOnDggB566CH5+PjI09NTzZo104kTJ+yeLa/3X4vForfeesuuuS5evKghQ4aoUqVK8vDwUJ06dTR37txizVTQbMnJyerXr5+Cg4NVunRpdezYsUTecwvyvfHq1auKiYlRuXLlVKZMGfXs2VPJyckOkW3evHlq06aNvL29ZbFYlJqaWuy5CpLt3LlzGjp0qGrWrCkPDw+FhIToueeeU1pamt2zSdI//vEPVatWTR4eHqpQoYK6deumgwcP2j1XDsMw1KlTp2LvWBT7EvTpp59qxIgRGjdunHbu3KmGDRsqMjJSKSkp9o6mS5cuqWHDhpo9e7a9o9jYtGmTYmJi9MMPPyguLk6ZmZnq0KGDLl26ZO9oqlSpkt58800lJCRox44dateunbp166Z9+/bZO5rV9u3b9f7776tBgwb2jmJVt25dnTlzxnr77rvv7B1JknT+/Hm1bNlSLi4u+vrrr7V//369/fbbKlu2rL2jafv27TavWVxcnCTp0UcftWuuyZMna86cOXr33Xd14MABTZ48WVOmTNGsWbNKPMvt3sOmTJmimTNnau7cudq6das8PT0VGRmpq1ev2j3bpUuX1KpVK02ePLnYs+S17Ftlu3z5snbu3KkxY8Zo586d+uKLL3To0CE99NBDds8mSXfddZfeffdd7dmzR999952qVKmiDh066LfffrNrrhzLli3TDz/8oODg4GLNc6OCZOvYsaPN+8l//vMfh8h29OhRtWrVSrVq1dLGjRu1e/dujRkzRu7u7nbPduPrdebMGX300UeyWCzq2bOnXXONGDFCq1ev1scff6wDBw5o+PDhGjJkiFauXFmsuW6XzTAMde/eXT///LNWrFihH3/8UaGhoYqIiCj2728F+d74/PPP68svv9Tnn3+uTZs26fTp0+rRo0ex5ipotsuXL6tjx456+eWXiz3PnWQ7ffq0Tp8+ralTp2rv3r1asGCBVq9erQEDBtg9myQ1adJE8+fP14EDB/TNN9/IMAx16NBBWVlZds2VY8aMGbJYLMWWxcpAiWnevLkRExNjvZ+VlWUEBwcbkyZNsmOq3CQZy5Yts3eMPKWkpBiSjE2bNtk7Sp7Kli1r/Otf/7J3DMMwDOPChQtGjRo1jLi4OOP+++83hg0bZu9Ixrhx44yGDRvaO0aeRo0aZbRq1creMQpk2LBhRrVq1Yzs7Gy75ujcubPx1FNP2Uzr0aOHERUVZadEf7j5PSw7O9sIDAw03nrrLeu01NRUw83NzfjPf/5j12w3OnbsmCHJ+PHHH0s0U46CvPdv27bNkGQcP368ZEL9n4JkS0tLMyQZa9euLZlQxq1z/frrr0bFihWNvXv3GqGhocb06dNLLFN+2aKjo41u3bqVeJab5ZWtd+/exhNPPGGfQDcoyO9at27djHbt2pVMoP+TV666desasbGxNtPuvvtu45VXXinBZLmzHTp0yJBk7N271zotKyvLqFChgvHBBx+UaLabvzempqYaLi4uxueff24dc+DAAUOSER8fb9dsN9qwYYMhyTh//nyJZspRkO/bn332meHq6mpkZmaWYLKCZdu1a5chyThy5Ijdc/34449GxYoVjTNnzhR7x2KLfQnJyMhQQkKCIiIirNOcnJwUERGh+Ph4OyYzl5xdfvz8/OycxFZWVpY++eQTXbp0SeHh4faOI0mKiYlR586dbX7nHMHhw4cVHBysqlWrKioqqkR2syyIlStXqmnTpnr00Ufl7++vxo0b64MPPrB3rFwyMjL08ccf66mnniqZv/7m495779W6dev0008/SZJ27dql7777Tp06dbJrrpsdO3ZMSUlJNv8v+Pj4qEWLFrz/3qG0tDRZLBb5+vraO4qNjIwMzZs3Tz4+PmrYsKFds2RnZ+vJJ5/UyJEjVbduXbtmycvGjRvl7++vmjVravDgwTp79qy9Iyk7O1v/+9//dNdddykyMlL+/v5q0aKFwxwWeKPk5GT973//K5Etlbdz7733auXKlTp16pQMw9CGDRv0008/qUOHDnbNde3aNUmy2dvCyclJbm5uJb6X3s3fGxMSEpSZmWnzeVCrVi2FhISU+OeBo36nlQqWLS0tTd7e3nJ2di6pWNblSrfOdunSJc2fP19hYWGqXLmyXXNdvnxZjz/+uGbPnq3AwMBiz0CxLyG///67srKyFBAQYDM9ICBASUlJdkplLtnZ2Ro+fLhatmypevXq2TuOJGnPnj0qU6aM3Nzc9Mwzz2jZsmWqU6eOvWPpk08+0c6dOzVp0iR7R7HRokUL6+5bc+bM0bFjx3TffffpwoUL9o6mn3/+WXPmzFGNGjX0zTffaPDgwXruuee0cOFCe0ezsXz5cqWmpqpfv372jqKXXnpJffr0Ua1ateTi4qLGjRtr+PDhioqKsnc0Gznvsbz//jlXr17VqFGj9Nhjj8nb29vecSRJq1atUpkyZeTu7q7p06crLi5O5cuXt2umyZMny9nZWc8995xdc+SlY8eOWrRokdatW6fJkydr06ZN6tSpU7HurloQKSkpunjxot5880117NhRa9as0cMPP6wePXpo06ZNds12s4ULF8rLy6tEdt2+nVmzZqlOnTqqVKmSXF1d1bFjR82ePVutW7e2a66cojx69GidP39eGRkZmjx5sn799VedOXOmxHLk9b0xKSlJrq6uuf44WdKfB474nTZHQbL9/vvveu211zRo0CCHyfbee++pTJkyKlOmjL7++mvFxcXJ1dXVrrmef/553XvvverWrVuJ5CjZP7EAf0JMTIz27t3rMMdkS1LNmjWVmJiotLQ0LV26VNHR0dq0aZNdy/3Jkyc1bNgwxcXFlcixiXfixi25DRo0UIsWLRQaGqrPPvvM7ls/srOz1bRpU73xxhuSpMaNG2vv3r2aO3euoqOj7ZrtRh9++KE6depUosft3spnn32mxYsXa8mSJapbt64SExM1fPhwBQcHO9Rrhj8vMzNTvXr1kmEYmjNnjr3jWLVt21aJiYn6/fff9cEHH6hXr17aunWr/P397ZInISFB77zzjnbu3Gn3PWry0qdPH+u/69evrwYNGqhatWrauHGj2rdvb7dc2dnZkqRu3brp+eeflyQ1atRIW7Zs0dy5c3X//ffbLdvNPvroI0VFRTnE5+usWbP0ww8/aOXKlQoNDdXmzZsVExOj4OBgu+6t5+Lioi+++EIDBgyQn5+fSpUqpYiICHXq1KlET67qiN8bc5g5W3p6ujp37qw6depo/PjxDpMtKipKDzzwgM6cOaOpU6eqV69e+v7770vk/9W8cq1cuVLr16/Xjz/+WOzLz8EW+xJSvnx5lSpVKtdZN5OTk0tk1wyzGzJkiFatWqUNGzaoUqVK9o5j5erqqurVq6tJkyaaNGmSGjZsqHfeeceumRISEpSSkqK7775bzs7OcnZ21qZNmzRz5kw5OzvbfcvMjXx9fXXXXXfpyJEj9o6ioKCgXH+QqV27tsMcKiBJx48f19q1a/X000/bO4okaeTIkdat9vXr19eTTz6p559/3uH2FMl5j+X9t3BySv3x48cVFxfnMFvrJcnT01PVq1fXPffcow8//FDOzs768MMP7Zbn22+/VUpKikJCQqzvv8ePH9cLL7ygKlWq2C3XrVStWlXly5e3+3tw+fLl5ezs7PDvwd9++60OHTrkEO/BV65c0csvv6xp06apa9euatCggYYMGaLevXtr6tSp9o6nJk2aKDExUampqTpz5oxWr16ts2fPqmrVqiWy/Ft9bwwMDFRGRkaus82X5OeBo36nlW6f7cKFC+rYsaO8vLy0bNkyubi4OEw2Hx8f1ahRQ61bt9bSpUt18OBBLVu2zG651q9fr6NHj8rX19f6eSBJPXv2VJs2bYolC8W+hLi6uqpJkyZat26ddVp2drbWrVvnMMdkOyLDMDRkyBAtW7ZM69evV1hYmL0j5Ss7O9t6bJm9tG/fXnv27FFiYqL11rRpU0VFRSkxMVGlSpWya74bXbx4UUePHlVQUJC9o6hly5a5LlPy008/KTQ01E6Jcps/f778/f3VuXNne0eR9MexY05Oth8jpUqVsm59cxRhYWEKDAy0ef9NT0/X1q1bef+9jZxSf/jwYa1du1blypWzd6R82fs9+Mknn9Tu3btt3n+Dg4M1cuRIffPNN3bLdSu//vqrzp49a/f3YFdXVzVr1szh34M//PBDNWnSxO7ncZD++H8zMzPT4d+DfXx8VKFCBR0+fFg7duwo9l2Sb/e9sUmTJnJxcbH5PDh06JBOnDhR7J8HjvydtiDZ0tPT1aFDB7m6umrlypUlttdKYV43wzBkGEaxfh7cLtdLL72U6/NAkqZPn6758+cXSyZ2xS9BI0aMUHR0tJo2barmzZtrxowZunTpkvr372/vaLp48aLNX+yPHTumxMRE+fn5KSQkxG65YmJitGTJEq1YsUJeXl7W4598fHzk4eFht1ySNHr0aHXq1EkhISG6cOGClixZoo0bN9r9y5uXl1eu4448PT1Vrlw5ux/H9c9//lNdu3ZVaGioTp8+rXHjxqlUqVJ67LHH7JpL+v/HQb3xxhvq1auXtm3bpnnz5mnevHn2jibpj8Iyf/58RUdHl/iJam6la9eumjhxokJCQlS3bl39+OOPmjZtmp566qkSz3K797Dhw4fr9ddfV40aNRQWFqYxY8YoODhY3bt3t3u2c+fO6cSJE9brw+eUm8DAwGLfgpRftqCgID3yyCPauXOnVq1apaysLOt7sJ+fX7Efu5hftnLlymnixIl66KGHFBQUpN9//12zZ8/WqVOniv0ykLf7ed78xw8XFxcFBgaqZs2axZrrdtn8/Pw0YcIE9ezZU4GBgTp69KhefPFFVa9eXZGRkXbNFhISopEjR6p3795q3bq12rZtq9WrV+vLL7/Uxo0b7Z5N+qPUfP7553r77beLPU9Bc91///0aOXKkPDw8FBoaqk2bNmnRokWaNm2a3bN9/vnnqlChgkJCQrRnzx4NGzZM3bt3L/YT+93ue6OPj48GDBigESNGyM/PT97e3ho6dKjCw8N1zz332DWb9Mc5AJKSkqyv7Z49e+Tl5aWQkJBiPcne7bLllPrLly/r448/Vnp6utLT0yVJFSpUKNaNRrfL9vPPP+vTTz9Vhw4dVKFCBf36669688035eHhoQcffNBuuW71GR4SElJ8f9QptvPtI0+zZs0yQkJCDFdXV6N58+bGDz/8YO9IhmH8/8tq3HyLjo62a668Mkky5s+fb9dchmEYTz31lBEaGmq4uroaFSpUMNq3b2+sWbPG3rHy5CiXu+vdu7cRFBRkuLq6GhUrVjR69+5dopciuZ0vv/zSqFevnuHm5mbUqlXLmDdvnr0jWX3zzTeGJOPQoUP2jmKVnp5uDBs2zAgJCTHc3d2NqlWrGq+88opx7dq1Es9yu/ew7OxsY8yYMUZAQIDh5uZmtG/fvsRey9tlmz9/fp7zx40bZ9dsOZffy+u2YcMGu2a7cuWK8fDDDxvBwcGGq6urERQUZDz00EPGtm3b7JorLyV5ubv8sl2+fNno0KGDUaFCBcPFxcUIDQ01Bg4caCQlJdk9W44PP/zQqF69uuHu7m40bNjQWL58ucNke//99w0PDw8jNTW1RDIVJNeZM2eMfv36GcHBwYa7u7tRs2ZN4+233y6RS6HeLts777xjVKpUyXBxcTFCQkKMV199tUQ+GwryvfHKlSvGs88+a5QtW9YoXbq08fDDDxtnzpxxiGzjxo2zy/fe22W71c9bknHs2DG7Zjt16pTRqVMnw9/f33BxcTEqVapkPP7448bBgwftmutWjynOy91Z/m8hAAAAAADAhDjGHgAAAAAAE6PYAwAAAABgYhR7AAAAAABMjGIPAAAAAICJUewBAAAAADAxij0AAAAAACZGsQcAAAAAwMQo9gAAAAAAmBjFHgAAFIsFCxbI19f3Tz+PxWLR8uXL//TzAADwV0WxBwAAt9SvXz91797d3jEAAEA+KPYAAAAAAJgYxR4AABTKtGnTVL9+fXl6eqpy5cp69tlndfHixVzjli9frho1asjd3V2RkZE6efKkzfwVK1bo7rvvlru7u6pWraoJEybo+vXrJbUaAACYHsUeAAAUipOTk2bOnKl9+/Zp4cKFWr9+vV588UWbMZcvX9bEiRO1aNEiff/990pNTVWfPn2s87/99lv17dtXw4YN0/79+/X+++9rwYIFmjhxYkmvDgAApmUxDMOwdwgAAOCY+vXrp9TU1AKdvG7p0qV65pln9Pvvv0v64+R5/fv31w8//KAWLVpIkg4ePKjatWtr69atat68uSIiItS+fXuNHj3a+jwff/yxXnzxRZ0+fVrSHyfPW7ZsGcf6AwBwC872DgAAAMxp7dq1mjRpkg4ePKj09HRdv35dV69e1eXLl1W6dGlJkrOzs5o1a2Z9TK1ateTr66sDBw6oefPm2rVrl77//nubLfRZWVm5ngcAANwaxR4AANyxX375RV26dNHgwYM1ceJE+fn56bvvvtOAAQOUkZFR4EJ+8eJFTZgwQT169Mg1z93dvahjAwDwl0SxBwAAdywhIUHZ2dl6++235eT0xyl7Pvvss1zjrl+/rh07dqh58+aSpEOHDik1NVW1a9eWJN199906dOiQqlevXnLhAQD4i6HYAwCAfKWlpSkxMdFmWvny5ZWZmalZs2apa9eu+v777zV37txcj3VxcdHQoUM1c+ZMOTs7a8iQIbrnnnusRX/s2LHq0qWLQkJC9Mgjj8jJyUm7du3S3r179frrr5fE6gEAYHqcFR8AAORr48aNaty4sc3t3//+t6ZNm6bJkyerXr16Wrx4sSZNmpTrsaVLl9aoUaP0+OOPq2XLlipTpow+/fRT6/zIyEitWrVKa9asUbNmzXTPPfdo+vTpCg0NLclVBADA1DgrPgAAAAAAJsYWewAAAAAATIxiDwAAAACAiVHsAQAAAAAwMYo9AAAAAAAmRrEHAAAAAMDEKPYAAAAAAJgYxR4AAAAAABOj2AMAAAAAYGIUewAAAAAATIxiDwAAAACAiVHsAQAAAAAwsf8HuFEIl3rENIcAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(f'Image dimensions: 28 x 28 x 1') # image dimensions\n",
        "\n",
        "# classes and names\n",
        "num_classes = len(np.unique(y_train))\n",
        "label_map = {}\n",
        "ascii_val = 65\n",
        "for i in sorted(np.unique(y_train)):\n",
        "  if ascii_val == 74:   # if curr ascii is 74 = 'J', skip it\n",
        "    ascii_val += 1\n",
        "  label_map[int(i)] = chr(ascii_val)\n",
        "  ascii_val += 1\n",
        "\n",
        "print('Number of classes:', num_classes)\n",
        "print('Label map:', label_map)\n",
        "\n",
        "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "# print('\\nClass counts (label : count):')\n",
        "# print(class_counts.to_string())\n",
        "\n",
        "# stats for the training data set\n",
        "print(f\"Total number of images: {class_counts.sum()}\")\n",
        "print(f\"Average number of images per label: {class_counts.mean()}\")\n",
        "\n",
        "# class distribution histogram\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.countplot(x=y_train)\n",
        "plt.title('Class Distribution (training set)')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhRiUVEKuCvY"
      },
      "source": [
        "#Step 2: CNN Model Design + Step 3: Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZyFhd7G-i_k"
      },
      "outputs": [],
      "source": [
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train, 25)\n",
        "y_test = to_categorical(y_test, 25)\n",
        "\n",
        "# define a function to create and train a CNN model with custom hyperparameters and display results\n",
        "def train_and_display_cnn(filters=32, kernel_size=(3,3), pool_size=(2,2), epochs=5, experiment_name=\"Experiment\"):\n",
        "\n",
        "  global X_train, X_test, y_train, y_test\n",
        "\n",
        "  # Make local copies so we don't overwrite global variables by accident\n",
        "  X_train_local = X_train\n",
        "  X_test_local  = X_test\n",
        "  y_train_local = y_train\n",
        "  y_test_local  = y_test\n",
        "\n",
        "  # Create CNN model\n",
        "  model = Sequential([\n",
        "      Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(28,28,1)),\n",
        "      Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "      MaxPooling2D(pool_size=pool_size),\n",
        "      Dropout(0.25), # reduce overfitting\n",
        "\n",
        "      Conv2D(filters=filters*2, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "      Conv2D(filters=filters*2, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "      MaxPooling2D(pool_size=pool_size),\n",
        "      Dropout(0.25),\n",
        "\n",
        "      Flatten(),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(25, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Start timer for training\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  # if labels are integers (1-D), convert them to one-hot\n",
        "  if y_train.ndim == 1:\n",
        "    y_train = to_categorical(y_train, num_classes=25)\n",
        "  if y_test.ndim == 1:\n",
        "    y_test = to_categorical(y_test, num_classes=25)\n",
        "\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "  # Calculate training time\n",
        "  training_time = time.time() - start_time\n",
        "\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "  # Generate predictions for confusion matrix\n",
        "  y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "  y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "  # Generate confusion matrix\n",
        "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  class_report = classification_report(y_true, y_pred)\n",
        "\n",
        "  # sisplay results\n",
        "  print(f\"\\n--- {experiment_name} ---\")\n",
        "  print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "  print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(conf_matrix)\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9dGtqhcQ5EQ"
      },
      "source": [
        "#Step 3: Experiment and Improve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XfZLXOQSClb"
      },
      "source": [
        "###Experiment 1: Default Settings (32 filters, 3x3 kernel, 2x2 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xRmVb4pQ-n-",
        "outputId": "4f40011b-6813-419a-e81e-f0a8509283de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "--- Experiment 1: Default (32 filters, 3x3 kernel, 2x2 pool) ---\n",
            "Training Time: 28.35 seconds\n",
            "Test Accuracy: 0.9555\n",
            "Confusion Matrix:\n",
            "[[331   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 431   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 245   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 470   0   0   0   0   0   0   0   0   0   0   0   0  28\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 346   2   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 407   0   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 287   0   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 265   0   0   0   0   0   0  66   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 373   0   0   0   0   0  21\n",
            "    0   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0   0   0   0   0   0   1 246   0   0   0   0   2\n",
            "    0  21   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 347   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 164   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 144   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 246\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  13   0   0   0   0   0   0   0\n",
            "  214   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   6   0\n",
            "    0 255   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0\n",
            "    0   0 326   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  21 185   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0 266   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "    0   0  13  25   0 293]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       331\n",
            "           1       1.00      1.00      1.00       432\n",
            "           2       1.00      1.00      1.00       310\n",
            "           3       1.00      1.00      1.00       245\n",
            "           4       1.00      0.94      0.97       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       0.93      0.99      0.96       348\n",
            "           7       1.00      0.93      0.96       436\n",
            "           8       1.00      1.00      1.00       288\n",
            "          10       0.97      0.80      0.88       331\n",
            "          11       0.94      1.00      0.97       209\n",
            "          12       1.00      0.95      0.97       394\n",
            "          13       1.00      0.85      0.92       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       1.00      1.00      1.00       347\n",
            "          16       1.00      1.00      1.00       164\n",
            "          17       0.61      1.00      0.76       144\n",
            "          18       0.83      1.00      0.91       246\n",
            "          19       0.99      0.86      0.92       248\n",
            "          20       0.92      0.96      0.94       266\n",
            "          21       0.91      0.94      0.92       346\n",
            "          22       0.88      0.90      0.89       206\n",
            "          23       0.93      1.00      0.96       267\n",
            "          24       1.00      0.88      0.94       332\n",
            "\n",
            "    accuracy                           0.96      7172\n",
            "   macro avg       0.95      0.96      0.95      7172\n",
            "weighted avg       0.96      0.96      0.96      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=32, kernel_size=(3,3), pool_size=(2,2), epochs=5, experiment_name=\"Experiment 1: Default (32 filters, 3x3 kernel, 2x2 pool)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZPmie6HYSUP"
      },
      "source": [
        "###Experiment 2: Double the filters (64 filters, 3x3 kernel, 2x2 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voyypuBKYSUR",
        "outputId": "e014ecaa-1f74-40c6-b731-318a0ab4cf25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Experiment 2: Double the filters (64 filters, 3x3 kernel, 2x2 pool) ---\n",
            "Training Time: 37.53 seconds\n",
            "Test Accuracy: 0.9654\n",
            "Confusion Matrix:\n",
            "[[331   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 416   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  16   0   0   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 245   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 498   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 348   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  20 416   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 287   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0 310   0   0   0   0  10   0  11   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   7   0   0   0   0   0   0 366   0   0   0   0   0  21\n",
            "    0   0   0   0   0   0]\n",
            " [ 41   0   0   0   0   0   0   0   0   0   0  20 230   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 347   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 164   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 144   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0 226\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   0\n",
            "  207   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "    0 265   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 346   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 267   0]\n",
            " [  0   0   0   0   0   0   0   0  20   1   0   0   0   0   0   0   0   0\n",
            "    0   0  18   0   0 293]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94       331\n",
            "           1       1.00      0.96      0.98       432\n",
            "           2       1.00      1.00      1.00       310\n",
            "           3       1.00      1.00      1.00       245\n",
            "           4       0.99      1.00      0.99       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       0.95      1.00      0.97       348\n",
            "           7       1.00      0.95      0.98       436\n",
            "           8       0.93      1.00      0.96       288\n",
            "          10       0.99      0.94      0.96       331\n",
            "          11       0.91      1.00      0.95       209\n",
            "          12       0.90      0.93      0.92       394\n",
            "          13       1.00      0.79      0.88       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       0.97      1.00      0.99       347\n",
            "          16       1.00      1.00      1.00       164\n",
            "          17       0.93      1.00      0.96       144\n",
            "          18       0.91      0.92      0.92       246\n",
            "          19       1.00      0.83      0.91       248\n",
            "          20       0.94      1.00      0.97       266\n",
            "          21       0.95      1.00      0.97       346\n",
            "          22       1.00      1.00      1.00       206\n",
            "          23       0.93      1.00      0.96       267\n",
            "          24       1.00      0.88      0.94       332\n",
            "\n",
            "    accuracy                           0.97      7172\n",
            "   macro avg       0.97      0.97      0.97      7172\n",
            "weighted avg       0.97      0.97      0.96      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=64, kernel_size=(3,3), pool_size=(2,2), epochs=5, experiment_name=\"Experiment 2: Double the filters (64 filters, 3x3 kernel, 2x2 pool)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q30iiStDYdDu"
      },
      "source": [
        "###Experiment 3: Double the epochs (32 filters, 3x3 kernel, 2x2 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbK8AQq2YdDv",
        "outputId": "ddb3f49a-d3f0-46bf-b6c0-9f7c1ca0f51b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "--- Experiment 3: Double the epochs (32 filters, 3x3 kernel, 2x2 pool) ---\n",
            "Training Time: 48.97 seconds\n",
            "Test Accuracy: 0.9681\n",
            "Confusion Matrix:\n",
            "[[331   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 411   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 245   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 493   0   0   0   0   0   0   0   0   0   0   0   0   5\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   4   0   0   0 308   0   0   0   0   0   0   0   0   0   0   0\n",
            "   36   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  20 416   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 288   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 306   0   0   0   0   0   0  10   0\n",
            "    0   0   0   0  15   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 394   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1 290   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 341   6   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  21   0   0   0 143   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 123   0\n",
            "    0   0  21   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0 245\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  227   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
            "    0 258   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 346   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 267   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  39   0   0 293]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       331\n",
            "           1       1.00      0.95      0.98       432\n",
            "           2       0.99      1.00      0.99       310\n",
            "           3       1.00      1.00      1.00       245\n",
            "           4       1.00      0.99      0.99       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       0.94      0.89      0.91       348\n",
            "           7       1.00      0.95      0.98       436\n",
            "           8       1.00      1.00      1.00       288\n",
            "          10       0.91      0.92      0.92       331\n",
            "          11       1.00      1.00      1.00       209\n",
            "          12       0.94      1.00      0.97       394\n",
            "          13       1.00      1.00      1.00       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       1.00      0.98      0.99       347\n",
            "          16       0.96      0.87      0.91       164\n",
            "          17       0.92      0.85      0.89       144\n",
            "          18       0.98      1.00      0.99       246\n",
            "          19       0.86      0.92      0.89       248\n",
            "          20       1.00      0.97      0.98       266\n",
            "          21       0.85      1.00      0.92       346\n",
            "          22       1.00      1.00      1.00       206\n",
            "          23       0.88      1.00      0.94       267\n",
            "          24       1.00      0.88      0.94       332\n",
            "\n",
            "    accuracy                           0.97      7172\n",
            "   macro avg       0.97      0.97      0.97      7172\n",
            "weighted avg       0.97      0.97      0.97      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=32, kernel_size=(3,3), pool_size=(2,2), epochs=10, experiment_name=\"Experiment 3: Double the epochs (32 filters, 3x3 kernel, 2x2 pool)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYwvC12TbIZ-"
      },
      "source": [
        "###Experiment 4: Larger Kernel Size (32 filters, 4x4 kernel, 2x2 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jWviG-XbIaA",
        "outputId": "5028da50-bdba-4325-8d40-9d5fe0851c32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Experiment 4: Larger Kernel Size (32 filters, 4x4 kernel, 2x2 pool) ---\n",
            "Training Time: 32.81 seconds\n",
            "Test Accuracy: 0.9642\n",
            "Confusion Matrix:\n",
            "[[310   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 421   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
            "    0   3   0   0   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 245   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 496   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 327   0   0   0   0   0   0   0   0   0   2   0\n",
            "   19   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  20 416   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 288   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 310   0   0   0   0   0   0   5   0\n",
            "    0   0   0   0   0  16]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   7   0   0   0   0   0   0 365  21   0   0   0   0   1\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 290   0   0   0   0   0\n",
            "    0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 347   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 164   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 124   0\n",
            "    0   0  20   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0 241\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  15   0   0   0   0   0   0   0   0   0   0\n",
            "  212   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  10   0\n",
            "    0 255   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0\n",
            "    0   0 326   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 267   0]\n",
            " [  0   0   0   0   0   0   0   0   0  19   0   0   0   0   0   0  20   0\n",
            "    0   0   0   0   0 293]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       331\n",
            "           1       1.00      0.97      0.99       432\n",
            "           2       1.00      1.00      1.00       310\n",
            "           3       1.00      1.00      1.00       245\n",
            "           4       0.99      1.00      0.99       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       0.94      0.94      0.94       348\n",
            "           7       0.97      0.95      0.96       436\n",
            "           8       1.00      1.00      1.00       288\n",
            "          10       0.92      0.94      0.93       331\n",
            "          11       1.00      1.00      1.00       209\n",
            "          12       1.00      0.93      0.96       394\n",
            "          13       0.86      1.00      0.92       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       1.00      1.00      1.00       347\n",
            "          16       1.00      1.00      1.00       164\n",
            "          17       0.69      0.86      0.76       144\n",
            "          18       0.99      0.98      0.98       246\n",
            "          19       0.92      0.85      0.89       248\n",
            "          20       0.98      0.96      0.97       266\n",
            "          21       0.94      0.94      0.94       346\n",
            "          22       1.00      1.00      1.00       206\n",
            "          23       0.93      1.00      0.96       267\n",
            "          24       0.95      0.88      0.91       332\n",
            "\n",
            "    accuracy                           0.96      7172\n",
            "   macro avg       0.96      0.96      0.96      7172\n",
            "weighted avg       0.97      0.96      0.96      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=32, kernel_size=(4,4), pool_size=(2,2), epochs=5, experiment_name=\"Experiment 4: Larger Kernel Size (32 filters, 4x4 kernel, 2x2 pool)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10jaiQzbeOX"
      },
      "source": [
        "###Experiment 5: Larger Pool Size (32 filters, 3x3 kernel, 3x3 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAQBnHYzbeOY",
        "outputId": "ac197b51-7271-45db-ab8b-5df02f7aca5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "--- Experiment 5: Larger Pool Size (32 filters, 3x3 kernel, 3x3 pool) ---\n",
            "Training Time: 27.56 seconds\n",
            "Test Accuracy: 0.9805\n",
            "Confusion Matrix:\n",
            "[[331   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 411   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  21   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 224   0   0   0   0   0   0   0   0   0   0   0   0  21   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 496   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 323  25   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   5 431   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 288   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 310   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   0  20]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 393   0   0   0   0   0   1\n",
            "    0   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0   0   0   0   0   0   0 270   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 347   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 164   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 144   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 246\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "  226   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0 265   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 346   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 267   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 332]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       331\n",
            "           1       1.00      0.95      0.98       432\n",
            "           2       1.00      1.00      1.00       310\n",
            "           3       1.00      0.91      0.96       245\n",
            "           4       1.00      1.00      1.00       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       0.98      0.93      0.96       348\n",
            "           7       0.95      0.99      0.97       436\n",
            "           8       1.00      1.00      1.00       288\n",
            "          10       1.00      0.94      0.97       331\n",
            "          11       1.00      1.00      1.00       209\n",
            "          12       1.00      1.00      1.00       394\n",
            "          13       1.00      0.93      0.96       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       1.00      1.00      1.00       347\n",
            "          16       1.00      1.00      1.00       164\n",
            "          17       0.86      1.00      0.93       144\n",
            "          18       0.99      1.00      0.99       246\n",
            "          19       1.00      0.91      0.95       248\n",
            "          20       1.00      1.00      1.00       266\n",
            "          21       1.00      1.00      1.00       346\n",
            "          22       0.91      1.00      0.95       206\n",
            "          23       0.93      1.00      0.96       267\n",
            "          24       0.94      1.00      0.97       332\n",
            "\n",
            "    accuracy                           0.98      7172\n",
            "   macro avg       0.98      0.98      0.98      7172\n",
            "weighted avg       0.98      0.98      0.98      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=32, kernel_size=(3,3), pool_size=(3,3), epochs=5, experiment_name=\"Experiment 5: Larger Pool Size (32 filters, 3x3 kernel, 3x3 pool)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wmu5pgwcDc6"
      },
      "source": [
        "###Experiment 6: Larger Kernel and Pool Size, Double the Epochs (32 filters, 5x5 kernel, 3x3 pool size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJqP0EW3cDc8",
        "outputId": "5920d82e-a437-4eeb-b51f-a3b307ebaad5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Experiment 6: Larger Kernel and Pool Size, Double the Epochs (32 filters, 5x5 kernel, 3x3 pool ---\n",
            "Training Time: 44.15 seconds\n",
            "Test Accuracy: 0.9788\n",
            "Confusion Matrix:\n",
            "[[331   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0 431   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0 310   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0 231  14   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0 498   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 323   8   0   0   0   0   0   0   4   0   0   0\n",
            "   13   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 436   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 288   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 331   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 394   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0 286   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 246   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 347   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 164   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   2   0   0   0   0   0   4   0   0  16   0   0   0  79   0\n",
            "    0  22  21   0   0   0]\n",
            " [  0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0 225\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  18   0   0   0   0   0   0   0\n",
            "  230   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0 263   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 346   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 267   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 332]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       331\n",
            "           1       1.00      1.00      1.00       432\n",
            "           2       1.00      1.00      1.00       310\n",
            "           3       0.99      0.94      0.96       245\n",
            "           4       0.93      1.00      0.97       498\n",
            "           5       1.00      1.00      1.00       247\n",
            "           6       1.00      0.93      0.96       348\n",
            "           7       0.98      1.00      0.99       436\n",
            "           8       1.00      1.00      1.00       288\n",
            "          10       0.99      1.00      0.99       331\n",
            "          11       0.92      1.00      0.96       209\n",
            "          12       1.00      1.00      1.00       394\n",
            "          13       0.95      0.98      0.96       291\n",
            "          14       1.00      1.00      1.00       246\n",
            "          15       0.99      1.00      0.99       347\n",
            "          16       1.00      1.00      1.00       164\n",
            "          17       0.98      0.55      0.70       144\n",
            "          18       1.00      0.91      0.96       246\n",
            "          19       0.95      0.93      0.94       248\n",
            "          20       0.92      0.99      0.95       266\n",
            "          21       0.94      1.00      0.97       346\n",
            "          22       1.00      1.00      1.00       206\n",
            "          23       1.00      1.00      1.00       267\n",
            "          24       1.00      1.00      1.00       332\n",
            "\n",
            "    accuracy                           0.98      7172\n",
            "   macro avg       0.98      0.97      0.97      7172\n",
            "weighted avg       0.98      0.98      0.98      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_display_cnn(filters=32, kernel_size=(3,3), pool_size=(3,3), epochs=10, experiment_name=\"Experiment 6: Larger Kernel and Pool Size, Double the Epochs (32 filters, 5x5 kernel, 3x3 pool\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D51MwSZni846"
      },
      "source": [
        "Dataset Overview:\n",
        "- The MNIST Sign-Language dataset has grayscale images (28x28), and 24 classes (A-Y excluding J and Z). J and Z signs were excluded because they require motions of the hand (videos/GIFs) and are not static images which are not being passed as an input to the CNN. The dataset has 27,445 total training images and 7172 test images. There are about 1144 images for each class on average for the training set.\n",
        "\n",
        "\n",
        "CNN Architecture:\n",
        "- The CNN model was designed to progressively learn features from the 28x28 grayscale images efficiently. It has two convolutional blocks where each has a max-pooling layer to reduce dimensions and a dropout layer to reduce overfitting by randomly disabling neurons while training so their learned weight goes to 0. ReLU was used as the activation function so that the model could learn non-linear patterns. We then flatten the resulting feature maps into a 1D vector which can be passed to a normal neural network. There is a final softmax function applied to the last layer to get the output probabilities for each of the classes.\n",
        "\n",
        "\n",
        "Accuracy/loss plots:\n",
        "- Most of the runs got an accuracy of about 95-98%. There were some errors that I believe can be fixed if given more computational resources and layers.\n",
        "\n",
        "\n",
        "Final test results:\n",
        "- Most of the runs had decent performance. The best run was Experiment 5, with larger pooling size.\n",
        "\n",
        "\n",
        "Reflection:\n",
        "What types of patterns did your CNN learn?\n",
        "- The CNN learnt low-level patterns like edges or outlines of the hand and fingers, curves, edges, etc and high-level patterns like the arrangement of fingers and palms that sign different letters. These kinds of spatial patterns is what CNNs are great at extracting from these grayscale images.\n",
        "\n",
        "What were the most common misclassifications?\n",
        "- The most common misclassifications I saw were H as G, K as R, N as A and U, and Y as X and V.\n",
        "\n",
        "What were your most important design trade-offs?\n",
        "- Complexity - The model only has 2 layers to cut down computational costs, but still provides a decent accuracy rate of 96%.\n",
        "- Dropouts - This reduces overfitting but slows down learning. It balances generalization well though.\n",
        "- Kernel and pooling sizes - using smaller sizes minimizes the number of parameters and makes computing faster but can be made more accurate by increasing it.\n",
        "\n",
        "How would you improve your model with more time, compute, or data?\n",
        "So far, the best experiment I ran was with an increase in pool size. We can improve the model performance by:\n",
        "- Adding more convolutional layers would make the model recognize even more hidden patterns.\n",
        "- If there was more data and time, we could train the CNN on a larger dataset, making it learn better.\n",
        "- We could add support for J and Z if we could extend the CNN to be able to learn motions from videos instead of just static images.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
